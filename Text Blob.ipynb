{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "\n",
    "\n",
    "\n",
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as **part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation**, and more.\n",
    "\n",
    "Installing textblob via :\n",
    "\n",
    "$ pip install -U textblob\n",
    "\n",
    "$ python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('titular', 'JJ'), ('threat', 'NN'), ('of', 'IN'), ('The', 'DT'), ('Blob', 'NNP'), ('has', 'VBZ'), ('always', 'RB'), ('struck', 'VBN'), ('me', 'PRP'), ('as', 'IN'), ('the', 'DT'), ('ultimate', 'JJ'), ('movie', 'NN'), ('monster', 'NN'), ('an', 'DT'), ('insatiably', 'RB'), ('hungry', 'JJ'), ('amoeba-like', 'JJ'), ('mass', 'NN'), ('able', 'JJ'), ('to', 'TO'), ('penetrate', 'VB'), ('virtually', 'RB'), ('any', 'DT'), ('safeguard', 'NN'), ('capable', 'JJ'), ('of', 'IN'), ('as', 'IN'), ('a', 'DT'), ('doomed', 'JJ'), ('doctor', 'NN'), ('chillingly', 'RB'), ('describes', 'VBZ'), ('it', 'PRP'), ('assimilating', 'VBG'), ('flesh', 'NN'), ('on', 'IN'), ('contact', 'NN'), ('Snide', 'JJ'), ('comparisons', 'NNS'), ('to', 'TO'), ('gelatin', 'VB'), ('be', 'VB'), ('damned', 'VBN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('a', 'DT'), ('concept', 'NN'), ('with', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('devastating', 'JJ'), ('of', 'IN'), ('potential', 'JJ'), ('consequences', 'NNS'), ('not', 'RB'), ('unlike', 'IN'), ('the', 'DT'), ('grey', 'NN'), ('goo', 'NN'), ('scenario', 'NN'), ('proposed', 'VBN'), ('by', 'IN'), ('technological', 'JJ'), ('theorists', 'NNS'), ('fearful', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('run', 'NN'), ('rampant', 'NN')]\n",
      "************************************************************\n",
      "['titular threat', 'blob', 'ultimate movie monster', 'amoeba-like mass', 'snide', 'potential consequences', 'grey goo scenario', 'technological theorists fearful', 'artificial intelligence run rampant']\n",
      "0.06000000000000001\n",
      "-0.34166666666666673\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "* Noun phrase extraction\n",
    "* Part-of-speech tagging\n",
    "* Sentiment analysis\n",
    "* Classification (Naive Bayes, Decision Tree)\n",
    "* Language translation and detection powered by Google Translate\n",
    "* Tokenization (splitting text into words and sentences)\n",
    "* Word and phrase frequencies\n",
    "* Parsing\n",
    "* n-grams\n",
    "* Word inflection (pluralization and singularization) and lemmatization\n",
    "* Spelling correction\n",
    "* Add new models or languages through extensions\n",
    "* WordNet integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part-of-speech Tagging\n",
    "\n",
    "blob = TextBlob(text)\n",
    "print(blob.tags)           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "print('***'*20)\n",
    "\n",
    "#Noun Phrase Extraction\n",
    "print(blob.noun_phrases)   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "        \n",
    "#Sentiment Analysis\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n",
    "# 0.060\n",
    "# -0.341\n",
    "\n",
    "#blob.translate(to=\"es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'titular', 'threat', 'of', 'The', 'Blob', 'has', 'always', 'struck', 'me', 'as', 'the', 'ultimate', 'movie', 'monster', 'an', 'insatiably', 'hungry', 'amoeba-like', 'mass', 'able', 'to', 'penetrate', 'virtually', 'any', 'safeguard', 'capable', 'of', 'as', 'a', 'doomed', 'doctor', 'chillingly', 'describes', 'it', 'assimilating', 'flesh', 'on', 'contact']\n",
      "['Snide', 'comparisons', 'to', 'gelatin', 'be', 'damned', 'it', \"'s\", 'a', 'concept', 'with', 'the', 'most', 'devastating', 'of', 'potential', 'consequences', 'not', 'unlike', 'the', 'grey', 'goo', 'scenario', 'proposed', 'by', 'technological', 'theorists', 'fearful', 'of', 'artificial', 'intelligence', 'run', 'rampant']\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"\n",
       " The titular threat of The Blob has always struck me as the ultimate movie\n",
       " monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
       " virtually any safeguard, capable of--as a doomed doctor chillingly\n",
       " describes it--\"assimilating flesh on contact.\"),\n",
       " Sentence(\"Snide comparisons to gelatin be damned, it's a concept with the most\n",
       " devastating of potential consequences, not unlike the grey goo scenario\n",
       " proposed by technological theorists fearful of\n",
       " artificial intelligence run rampant.\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Inflection and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Use', '4', 'spaces', 'per', 'indentation', 'level']\n",
      "**************************************************\n",
      "space\n",
      "**************************************************\n",
      "levels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence = TextBlob('Use 4 spaces per indentation level.')\n",
    "print(sentence.words)\n",
    "print('*****'*10)\n",
    "print(sentence.words[2].singularize())\n",
    "print('*****'*10)\n",
    "print(sentence.words[-1].pluralize())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet Integration\n",
    "\n",
    "You can access the synsets for a Word via the synsets property or the get_synsets method, optionally passing in a part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('octopus.n.01'), Synset('octopus.n.02')]\n",
      "[Synset('chop.v.05'), Synset('hack.v.02'), Synset('hack.v.03'), Synset('hack.v.04'), Synset('hack.v.05'), Synset('hack.v.06'), Synset('hack.v.07'), Synset('hack.v.08')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"octopus\")\n",
    "print(word.synsets)\n",
    "\n",
    "print(Word(\"hack\").get_synsets(pos=VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the definitions for each synset via the definitions property or the define() method, which can also take an optional part-of-speech argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tentacles of octopus prepared as food', 'bottom-living cephalopod having a soft oval body with eight long tentacles']\n"
     ]
    }
   ],
   "source": [
    "print(Word(\"octopus\").definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "\n",
    "Use the correct() method to attempt spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling! , can you pus correct the mistakes i had made in this sentence\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling! , can yuouo pls correct the mistankes i had made in thsi ssentence\")\n",
    "print(b.correct())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('falibility')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "The TextBlob.ngrams() method returns a list of tuples of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Start and End Indices of Sentences\n",
    "Use sentence.start and sentence.end to get the indices where a sentence starts and ends within a TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now is better than never.\n",
      "---- Starts at index 0, Ends at index 25\n"
     ]
    }
   ],
   "source": [
    "for s in blob.sentences:\n",
    "...     print(s)\n",
    "...     print(\"---- Starts at index {}, Ends at index {}\".format(s.start, s.end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
