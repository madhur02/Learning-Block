{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini\n",
      "Expected_Phrase_Sentence\n",
      "Final_Report.py\n",
      "Input_Corpus\n",
      "Input_Files\n",
      "output_10K_analysis.xlsx\n",
      "Output_Result\n",
      "phrase_file - Copy.txt\n",
      "phrase_file.txt\n",
      "rahul.csv\n",
      "remainnig_input files\n",
      "sentence_Phrase_Wrapper.py\n",
      "Sentence_Similarty_Pooing_row.py\n",
      "Sentence_Similarty_v1.py\n",
      "stanford_parser.py\n",
      "word2_vec.pickle\n",
      "word_2_vec_v1.py\n",
      "__pycache__\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Open a file\n",
    "path = r\"C:\\Users\\Desktop\\Similarity model\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# This would print all the files and directories\n",
    "for file in dirs:\n",
    "    print( file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple text files content.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import errno\n",
    "path = r\"C:\\Users\\Desktop\\Phrases\\*.txt\"\n",
    "files = glob.glob(path)\n",
    "print('these are the list of file', files)\n",
    "for name in files:\n",
    "    try:\n",
    "        with open(name) as f:\n",
    "            for line in f:\n",
    "                words = list()\n",
    "                for word in line.split():\n",
    "                    words.append(word)\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR:\n",
    "            raise\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r\"C:\\Users\\madhur\\Desktop\\data\"\n",
    "all_files = []\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(\".txt\"):\n",
    "        all_files.append(f)\n",
    "all_text = []\n",
    "print(\"This is the all_files.txt\" , all_files)\n",
    "\n",
    "for file in  all_files:\n",
    "    path1 = os.path.join(path,file)\n",
    "    print(path1)\n",
    "    \n",
    "    with open(path1) as data_file:\n",
    "        try:\n",
    "            data = data_file.readlines()\n",
    "            all_text.append(data)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(all_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Desktop\\\\Hash-T\\\\Review Dataset\\\\positive_review\"\n",
    "\n",
    "csv_path = \"positive_review.csv\"\n",
    "\n",
    "all_json_files = os.listdir(path)\n",
    "\n",
    "all_text = []\n",
    "\n",
    "for json_file in  all_json_files:\n",
    "    json_path = os.path.join(path,json_file)\n",
    "    with open(json_path, encoding='utf-8') as data_file:\n",
    "        try:\n",
    "            data = json.loads(data_file.read())\n",
    "\n",
    "            txt = data[\"text\"]\n",
    "            language = data[\"language\"].lower()\n",
    "            if language == \"english\":\n",
    "                all_text.append([txt,\"positive\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "New_df = pd.DataFrame(all_text,columns=['text',\"Actual-Prediction\"])\n",
    "New_df.to_csv(csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
